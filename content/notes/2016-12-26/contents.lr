title: 새해 공부하고 싶은 것들
---
pub_date: 2016-12-26
---
body:

<h3>기계학습</h3>

1. 강화학습  
범용지능을 위해선 지금보다 유연한 학습 인터페이스가 필요하단 생각을 매번 한다. 새로 산 책을 시작으로 딥러닝에 접목되고 있는 최근 연구까지 깊게 공부해보고 싶다.

2. Neural Turing Machine  
강화학습이 방법론의 미래라면, NTM은 아키텍처의 미래라는 인상을 받는다. DeepMind의 [논문](https://arxiv.org/abs/1410.5401)을 읽었을 때 그런 신선한 충격을 받았다. 최근엔 어떤 연구가 이루어지고 있는지 궁금하다.

3. Attention 그리고 Adversarial Training   
둘 다 직관적인 아이디어에 기반을 둔 방법론이다. 특히 Attention 같은 경우 사람의 심리학적 현상을 모방한다는 점이 참 재미있다. Adversarial Training도 적대적인 두 네트워크를 대련시키면 네트워크를 학습시킬 수 있을거라는 그 생각이 단순하고 직관적이어서 좋다. 직관적인 이론과 모델은 언제나 매력적이다.

4. Generative Model  
이미지 생성, 음악작곡 그리고 텍스트 생성처럼 재밌는 프로젝트는 대개 Generative Model을 사용해야 구현이 가능하다. 공부하면서 Generative Model을 이용한 프로젝트를 한두 개 정도 해보고 싶다.

5. 통계학  
학습방법론을 연구하는 논문을 읽다보면 '이렇게 해보니 잘 되더라' 라는 식의 전개가 많은 것 처럼 느껴졌다. 다른 분야에 비해 수학적 엄밀함이 부족한 것 같다. 뿌리깊은 나무가 높이 자란다. 사상누각의 학자가 되어서는 안되겠다.


<h3>그 외</h3>

1. Haskell  
1년 전 재미삼아 공부하면서 느꼈던 지적 흥분을 다시 느껴보고싶다. 여러 언어를 공부해봤지만 단언컨데 그중 가장 철학적으로 섹시한 언어였다. 내년엔 간단한 서비스 하나 정도를 Haskell로 개발해보고 싶다.

2. 범주론  
Haskell의 TypeClass와 그 이론적 배경을 공부하면서 흥미를 느꼈다. 한 번쯤 깊게 공부해보고 싶다. 집합론 강의를 함께 들으면서 공부하면 좋겠다.

3. GRE  
하고싶다기보단 해야하는 일이다. 복학 후 연구실 생활과 학점관리에만 집중할 수 있게 미리 해결해놓자.
